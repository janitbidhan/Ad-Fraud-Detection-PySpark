{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Connect with Google Drive for loading Data.**"
      ],
      "metadata": {
        "id": "Gjx5BZ3I3edF"
      },
      "id": "Gjx5BZ3I3edF"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IxFy-PG43dEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fee5102-3c92-4d90-bad6-fb82c1d62cc7"
      },
      "id": "IxFy-PG43dEn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Spark Session**"
      ],
      "metadata": {
        "id": "rppzR4En3hIq"
      },
      "id": "rppzR4En3hIq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92bb6724-ac54-47a8-aa3b-c6f01d4ecb8f",
      "metadata": {
        "id": "92bb6724-ac54-47a8-aa3b-c6f01d4ecb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "afebbab7-28c8-4a7b-b600-8453379354f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 55.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=92463305f8e6c3247f793f527d7f78beb8b89f1e2427d7f6813885f2328edc3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f0cf6314f70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7f25452d74f2:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MapReduce-Project-Fraud-Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config(\"spark.driver.memory\", \"25g\").\\\n",
        "config('spark.executor.memory', '25G').\\\n",
        "config('spark.driver.maxResultSize', '25G').\\\n",
        "appName(\"MapReduce-Project-Fraud-Analysis\").getOrCreate()\n",
        "spark.conf.set('spark.sql.pivotMaxValues', u'1000000')\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
        "spark.conf.set(\"spark.sql.inMemoryColumnarStorage.compressed\", True)\n",
        "spark.conf.set(\"spark.sql.inMemoryColumnarStorage.batchSize\",10000)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n",
        "\n",
        "1.   **Installing Visualization Libraries.**\n",
        "2.   **Importing Spark**"
      ],
      "metadata": {
        "id": "UjZqxaY74G-u"
      },
      "id": "UjZqxaY74G-u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91672edd-6d1d-40f1-b38f-6e1da3090600",
      "metadata": {
        "id": "91672edd-6d1d-40f1-b38f-6e1da3090600",
        "outputId": "6781b81b-f55f-4ffc-c5f9-8e9fe8eea316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prettytable) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "#Libraries for Visualization purposesly\n",
        "!pip install seaborn\n",
        "!pip install prettytable\n",
        "\n",
        "#Imports\n",
        "from pyspark.sql.functions import row_number, count, isnan, countDistinct\n",
        "from pyspark.sql.window import *\n",
        "import random\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.window import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.linalg import VectorUDT\n",
        "from pyspark.sql.types import ArrayType, DoubleType,FloatType\n",
        "from pyspark.sql import Row, functions as F\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler,BucketedRandomProjectionLSH, VectorSlicer, VectorAssembler, StringIndexer, MinMaxScaler\n",
        "from pyspark.sql.functions import col, when, lit, udf, row_number, array, create_map, struct, explode\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.ml.classification import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "#For visualization purposes only\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Stats Functions\n",
        "\n",
        "\n",
        "1.   **checkNullsInData**: Returns percentage of rows with Null against the Total Rows\n",
        "2.   **checkNullPerTable**: Returns number of Null records full table.\n",
        "3. **getAttributeCount** : Returns the count for each label.\n",
        "4. **getCompleteSummary**: Returns the complete summary of the table."
      ],
      "metadata": {
        "id": "3oMlFGSYg_qc"
      },
      "id": "3oMlFGSYg_qc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "555be072-4526-4d7e-89ab-d0f416caa663",
      "metadata": {
        "id": "555be072-4526-4d7e-89ab-d0f416caa663"
      },
      "outputs": [],
      "source": [
        "# Percentage of rows with Null against the Total Rows\n",
        "def checkNullsInData(data):\n",
        "    # Show how many Null we have in the Dataframe\n",
        "    totalRows = data.count()\n",
        "    drop = data.na.drop().count()\n",
        "    print(\"Total: \", totalRows)\n",
        "    print(\"Left After Dropping:\", drop)\n",
        "    return (totalRows - drop) / totalRows * 100\n",
        "\n",
        "\n",
        "#Number of Nulls full Table\n",
        "def checkNullPerTable(data):\n",
        "    # Show how many Null we have in the Dataframe\n",
        "    print(\"% Of Drops: \",checkNullsInData(data))\n",
        "    # this shows there are a lot of duplicacy in the data.# this shows there are a lot of duplicacy in the data.\n",
        "    # Lets see the percentage: \n",
        "    print(\"% of drop per column\")\n",
        "    return data.select([(count(when(isnan(c) | col(c).isNull(), c))*100/count(lit(1))).alias(c) for c in data.columns])\n",
        "\n",
        "# GET COUNT FOR EACH LABEL\n",
        "def getAttributeCount(data, label=\"is_attributed\"):\n",
        "    print(\"Stats for is attributed:\")\n",
        "    data.groupBy(label).count().show()\n",
        "\n",
        "# GET COMPLETE SUMMARY OF THE DATA\n",
        "def getCompleteSummary(data, label=\"is_attributed\"):\n",
        "    print(\"Summary\")\n",
        "    print(\"_________\")\n",
        "    data.summary().show()\n",
        "    print(\"_________\")\n",
        "    checkNullPerTable(data)\n",
        "    print(\"_________\")\n",
        "    print(\"Unique Values for each column in the table\")\n",
        "    data.agg(*(countDistinct(col(c)).alias(c) for c in data.columns)).show()\n",
        "    print(\"_________\")\n",
        "    print(\"Number of values in is_attributed for each label.\")\n",
        "    print(\"_________\")\n",
        "    getAttributeCount(data, label)\n",
        "    print(\"_________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393c3d08-4d39-47c6-8105-3e616a8a878e",
      "metadata": {
        "id": "393c3d08-4d39-47c6-8105-3e616a8a878e"
      },
      "source": [
        "## Utility Functions\n",
        "1. **getFeaturesData**: For returning Vectorized features and label. It also drops exta coulmns if required.\n",
        "2. **findImbalance** : It is used for finding imbalance ratio between the two labels and returns the data Not Fraud, data Fraud, ratio\n",
        "3. **vectorizeData** : Returns Vector Assembled feature by merging all feature columns.\n",
        "4. **stratifiedTrainTestSplit**: It is used for splitting the sampled dataset randomly in 80:20 ratio where 80 is for Training and 20 is for Testing "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeaturesData(\n",
        "    data, inputColumnsList=[\"ip\", \"app\", \"device\", \"os\", \"channel\"], drop=False\n",
        "):\n",
        "    va = VectorAssembler(inputCols=inputColumnsList, outputCol=\"features\")\n",
        "    transformedData = va.transform(data)\n",
        "    if drop:\n",
        "        return (\n",
        "            va.transform(data)\n",
        "            .drop(*inputColumnsList)\n",
        "            .withColumnRenamed(\"is_attributed\", \"label\")\n",
        "        )\n",
        "    return va.transform(data)\n",
        "\n",
        "#It is used for finding imbalance ratio between the two labels and returns the data Not Fraud, data Fraud, ratio\n",
        "def findImbalance(data):\n",
        "    dataNotFraud = data.filter(col(\"is_attributed\") == 0)\n",
        "    dataFraud = data.filter(col(\"is_attributed\") == 1)\n",
        "    countFraud = dataFraud.count()\n",
        "    countNotFraud = dataNotFraud.count()\n",
        "    ratio = int(countNotFraud / countFraud)\n",
        "    print(\n",
        "        \"Count Fraud: {}\\nCount Not Fraud: {}\\nRatio: {}\".format(\n",
        "            countFraud, countNotFraud, ratio\n",
        "        )\n",
        "    )\n",
        "    return dataNotFraud, dataFraud, ratio\n",
        "\n",
        "\n",
        "#\n",
        "def vectorizeData(data, NumericColumns, targetColumn):\n",
        "    if data.select(targetColumn).distinct().count() != 2:\n",
        "        raise ValueError(\"Target col must have exactly 2 classes\")\n",
        "    if targetColumn in NumericColumns:\n",
        "        NumericColumns.remove(targetColumn)\n",
        "    assembler = VectorAssembler(inputCols=NumericColumns, outputCol=\"features\")\n",
        "    vectorizedData = assembler.transform(data)\n",
        "    keepColumns = [a for a in vectorizedData.columns if a not in NumericColumns]\n",
        "    return (\n",
        "        vectorizedData.select(*keepColumns)\n",
        "        .withColumn(\"label\", vectorizedData[targetColumn])\n",
        "        .drop(targetColumn)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "#It is used for splitting the sampled dataset randomly in 80:20 ratio where 80 is for Training and 20 is for Testing\n",
        "def stratifiedTrainTestSplit(data, ifprint=False):\n",
        "    print(\"\\n-----TRAIN TEST SPLIT STARTED----\")\n",
        "    dataNotFraud, dataFraud, ratio= findImbalance(data)\n",
        "    dataNotFraudTrain,dataNotFraudTest=dataNotFraud.randomSplit([0.8, 0.2])\n",
        "    dataFraudTrain,dataFraudTest=dataFraud.randomSplit([0.8, 0.2])\n",
        "    train = dataNotFraudTrain.union(dataFraudTrain)\n",
        "    test = dataFraudTest.union(dataNotFraudTest)\n",
        "    if print:\n",
        "        print(\"\\n----SAMPLES IN TRAIN----\")\n",
        "        dataNotFraud, dataFraud, ratio= findImbalance(train)\n",
        "        print(\"\\n----SAMPLES IN TEST-----\")\n",
        "        dataNotFraud, dataFraud, ratio= findImbalance(test)\n",
        "    return train , test"
      ],
      "metadata": {
        "id": "Y57RLDru4S4v"
      },
      "id": "Y57RLDru4S4v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Sampling Functions\n",
        "1. **randomOverSample**: It takes the ratio and does random over sampling of the lower count label to match as the higher count label as per the ratio and returns the vectorized data.\n",
        "2. **randomUnderSamplingWithoutTransformation**:  It takes the ratio and does random over sampling of the lower count label to match as the higher count label as per the ratio and returns the data.\n",
        "3. **randomUnderSamplingStratified**: It is used for doing undersampling in a stratified way keeping percentage of labels as per rates r1 and r2, It returns the combined data.\n",
        "4. **randomUnderSampling**:  It takes the ratio and does random under sampling of the decrease the higher count label to match as per the ratio.\n",
        "5. **randomUnderSamplingWithoutTransformation**: It takes the ratio and does random over sampling of the lower count label to match as per the ratio to the higher count label and returns the data.\n",
        "6. **randomUnderSamplingStratified** : It is used for undersampled in a stratified way keeping percentage of labels as per rates r1 and r2, It returns the combined data.\n",
        "7. **randomUnderSampling** : It takes the ratio and does random under sampling of the decrease the higher count label to match as per the ratio.\n",
        "8. **completeOverSampling** : It duplicates the minority class records to match the passed ratio."
      ],
      "metadata": {
        "id": "Y46hQZm-4oti"
      },
      "id": "Y46hQZm-4oti"
    },
    {
      "cell_type": "code",
      "source": [
        "# It takes the ratio and does random over sampling of the lower count label to match as the higher count label as per the ratio.\n",
        "def randomOverSample(dataNotFraud, dataFraud, ratio):\n",
        "    dataFraud = dataFraud.sample(True, float(ratio), 24)\n",
        "    totalData = dataFraud.unionAll(dataNotFraud)\n",
        "    return getFeaturesData(totalData, drop=True)\n",
        "\n",
        "#It takes the ratio and does random over sampling of the lower count label to match as per the ratio to the higher count label and returns the data.\n",
        "def randomUnderSamplingWithoutTransformation(dataNotFraud, dataFraud, ratio):\n",
        "    dataNotFraud = dataNotFraud.sample(False, 1 / ratio, 24)\n",
        "    return dataNotFraud.unionAll(dataFraud)\n",
        "\n",
        "# It is used for undersampled in a stratified way keeping percentage of labels as per rates r1 and r2, It returns the combined data.\n",
        "def randomUnderSamplingStratified(data, r1=0.1, r2=0.4):\n",
        "    dataNotFraudSampled = data.filter(col(\"is_attributed\") == 0).sample(False, r1)\n",
        "    dataFraudSampled = data.filter(col(\"is_attributed\") == 1).sample(False, r2)\n",
        "    out = dataNotFraudSampled.union(dataFraudSampled)\n",
        "    return out\n",
        "\n",
        "# It takes the ratio and does random under sampling of the decrease the higher count label to match as per the ratio.\n",
        "def randomUnderSampling(dataNotFraud, dataFraud, ratio):\n",
        "    dataNotFraud = dataNotFraud.sample(False, 1 / ratio, 24)\n",
        "    totalData = dataNotFraud.unionAll(dataFraud)\n",
        "    return getFeaturesData(totalData, drop=True)\n",
        "\n",
        "\n",
        "def completeOverSampling(dataNotFraud, dataFraud, ratio):\n",
        "    a = range(ratio)\n",
        "    # duplicate the minority rows\n",
        "    oversampledData = dataFraud.withColumn(\n",
        "        \"test\", explode(array([lit(x) for x in a]))\n",
        "    ).drop(\"test\")\n",
        "    # combine both oversampled minority rows and previous majority rows combined_df = major_df.unionAll(oversampled_df)\n",
        "    totalData = dataNotFraud.unionAll(oversampledData)\n",
        "    return getFeaturesData(totalData, drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WPjG02x_4plZ"
      },
      "id": "WPjG02x_4plZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE: Synthetic Minority Over-sampling Technique Implementation\n",
        "\n",
        "1. **checkValidityOfColumnsCheck**: Checking validity of functions, if all columns are correctly type identified.\n",
        "2. **getNumericCategoricalColumns**: Returns the lists of numerical and string columns.\n",
        "3. **smote**: Used above mentioned utlity functions in implementing custom function for SMOTE "
      ],
      "metadata": {
        "id": "OsdoyxhG4s1j"
      },
      "id": "OsdoyxhG4s1j"
    },
    {
      "cell_type": "code",
      "source": [
        "# Utlity functions of SMOTE\n",
        "\n",
        "\n",
        "#Checking validity of functions, if all columns are correctly type identified.\n",
        "def checkValidityOfColumnsCheck(allColumns, data):\n",
        "    if len(set(allColumns)) == len(data.columns):\n",
        "        print(\"All columns are been covered.\")\n",
        "    elif len(set(allColumns)) < len(data.columns):\n",
        "        not_handle_list = list(set(data.columns) - set(allColumns))\n",
        "        print(\n",
        "            \"Not all columns are covered,The columns missed out: {0}\".format(\n",
        "                not_handle_list\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        mistake_list = list(set(allColumns) - set(data.columns))\n",
        "        print(\"The columns been hardcoded wrongly: {0}\".format(mistake_list))\n",
        "\n",
        "\n",
        "#Returns the lists of numerical and string columns.\n",
        "def getNumericCategoricalColumns(data, excludedList=[]):\n",
        "    timestampColumns = [\n",
        "        item[0] for item in data.dtypes if item[1].lower().startswith((\"time\", \"date\"))\n",
        "    ]\n",
        "    stringColumns = [\n",
        "        item[0]\n",
        "        for item in data.dtypes\n",
        "        if item[1].lower().startswith(\"string\")\n",
        "        and item[0] not in excludedList + timestampColumns\n",
        "    ]\n",
        "    numericColumns = [\n",
        "        item[0]\n",
        "        for item in data.dtypes\n",
        "        if item[1].lower().startswith((\"big\", \"dec\", \"doub\", \"int\", \"float\"))\n",
        "        and item[0] not in excludedList + timestampColumns\n",
        "    ]\n",
        "    allColumns = timestampColumns + stringColumns + numericColumns + excludedList\n",
        "    checkValidityOfColumnsCheck(allColumns, data)\n",
        "    return numericColumns, stringColumns\n",
        "\n",
        "\n",
        "\n",
        "# Synthetic Minority Over-sampling Technique Implementation \n",
        "def smote(dataInit, seed, bucketLength, k, multiplier):\n",
        "    NumericColumns, CatColumns = getNumericCategoricalColumns(dataInit)\n",
        "    data = vectorizeData(dataInit, NumericColumns, targetColumn=\"is_attributed\")\n",
        "    dataInputFraud = data[data[\"label\"] == 1]\n",
        "\n",
        "    # LSH, bucketed random projection\n",
        "    bucketedRandomProjection = BucketedRandomProjectionLSH(\n",
        "        inputCol=\"features\", outputCol=\"hashes\", seed=seed, bucketLength=bucketLength\n",
        "    )\n",
        "    # smote only applies on existing minority instances\n",
        "    model = bucketedRandomProjection.fit(dataInputFraud)\n",
        "    model.transform(dataInputFraud)\n",
        "\n",
        "    # here distance is calculated from bucketedRandomProjection's param inputCol\n",
        "    selfJoinWithDistance = model.approxSimilarityJoin(\n",
        "        dataInputFraud, dataInputFraud, float(\"inf\"), distCol=\"EuclideanDistance\"\n",
        "    )\n",
        "    # remove self-comparison (distance 0)\n",
        "    selfJoinWithDistance = selfJoinWithDistance.filter(\n",
        "        selfJoinWithDistance.EuclideanDistance > 0\n",
        "    )\n",
        "    overOriginalRows = Window.partitionBy(\"datasetA\").orderBy(\"EuclideanDistance\")\n",
        "    selfSimilarity = selfJoinWithDistance.withColumn(\n",
        "        \"r_num\", F.row_number().over(overOriginalRows)\n",
        "    )\n",
        "    selfSimilaritySelected = selfSimilarity.filter(selfSimilarity.r_num <= k)\n",
        "    overOriginalRowsNoOrder = Window.partitionBy(\"datasetA\")\n",
        "\n",
        "    # list to store batches of synthetic data\n",
        "    res = []\n",
        "    # two udf for vector add and subtract, subtraction include a random factor [0,1]\n",
        "    subtractVectorUDF = F.udf(\n",
        "        lambda arr: random.uniform(0, 1) * (arr[0] - arr[1]), VectorUDT()\n",
        "    )\n",
        "    addVectorUDF = F.udf(lambda arr: arr[0] + arr[1], VectorUDT())\n",
        "\n",
        "    # retain original columns\n",
        "    originalColumns = dataInputFraud.columns\n",
        "    print(\"Generating New Samples\")\n",
        "    for i in range(multiplier):\n",
        "        # logic to randomly select neighbour: pick the largest random number generated row as the neighbour\n",
        "        randomSelectedData = (\n",
        "            selfSimilaritySelected.withColumn(\"rand\", F.rand())\n",
        "            .withColumn(\"max_rand\", F.max(\"rand\").over(overOriginalRowsNoOrder))\n",
        "            .where(F.col(\"rand\") == F.col(\"max_rand\"))\n",
        "            .drop(*[\"max_rand\", \"rand\", \"r_num\"])\n",
        "        )\n",
        "        # create synthetic feature numerical part\n",
        "        vecDiff = randomSelectedData.select(\n",
        "            \"*\",\n",
        "            subtractVectorUDF(F.array(\"datasetA.features\", \"datasetB.features\")).alias(\n",
        "                \"vecdiff\"\n",
        "            ),\n",
        "        )\n",
        "        vecModified = vecDiff.select(\n",
        "            \"*\", addVectorUDF(F.array(\"datasetA.features\", \"vecdiff\")).alias(\"features\")\n",
        "        )\n",
        "        for c in originalColumns:\n",
        "            # randomly select neighbour or original data\n",
        "            colSubsititue = random.choice([\"datasetA\", \"datasetB\"])\n",
        "            val = \"{0}.{1}\".format(colSubsititue, c)\n",
        "            if c != \"features\":\n",
        "                # do not unpack original numerical features\n",
        "                vecModified = vecModified.withColumn(c, F.col(val))\n",
        "        vecModified = vecModified.drop(\n",
        "            *[\"datasetA\", \"datasetB\", \"vecdiff\", \"EuclideanDistance\"]\n",
        "        )\n",
        "        res.append(vecModified)\n",
        "    print(\"Samples Generation Complete.\")\n",
        "\n",
        "    unionedData = reduce(DataFrame.unionAll, res)\n",
        "    # union synthetic instances with original full (both minority and majority) data\n",
        "    return unionedData.union(data.select(unionedData.columns))"
      ],
      "metadata": {
        "id": "V3RLqUST4w5b"
      },
      "id": "V3RLqUST4w5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Models Implementation\n",
        "\n",
        "1. **LRModel** : Implements Logistic Regression with Cross Validation.\n",
        "2. **randomForest** : Implements Random Forrest Classifier with cross Validation.\n",
        "3. **LSVC**: Implents Linear Support Vector Machine with Cross Validation\n"
      ],
      "metadata": {
        "id": "ZDQHf0zt4wln"
      },
      "id": "ZDQHf0zt4wln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a399bff6-c937-4229-9bde-93140b7fdf0d",
      "metadata": {
        "id": "a399bff6-c937-4229-9bde-93140b7fdf0d"
      },
      "outputs": [],
      "source": [
        "#Implements Logistic Regression with Cross Validation.\n",
        "def LRModel(train,test, isCV=False):\n",
        "    print(\">>> LRModel Invoked\")\n",
        "    evaluator=BinaryClassificationEvaluator(labelCol='label')\n",
        "    lr = LogisticRegression(featuresCol='features',labelCol='label')\n",
        "    paramGrid = (ParamGridBuilder().addGrid(lr.maxIter, [20]).build())\n",
        "    fold=3\n",
        "    if isCV:\n",
        "        fold=10\n",
        "        paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]) \\\n",
        "                                 .addGrid(lr.maxIter, [10,20]) \\\n",
        "                                 .build())\n",
        "    cv = CrossValidator(estimator=lr,\n",
        "                              estimatorParamMaps=paramGrid,\n",
        "                              evaluator=evaluator,\n",
        "                              numFolds=fold) \n",
        "    model = cv.fit(train)\n",
        "    predictions = model.transform(test)\n",
        "    bestModel = model.bestModel\n",
        "    return {\"predictions\":predictions, \"bestModel\":bestModel}\n",
        "\n",
        "#Implements Random Forrest Classifier with cross Validation.\n",
        "def randomForest(train,test, isCV=False):\n",
        "    print(\">>> RandomForest Invoked\")\n",
        "    evaluator=BinaryClassificationEvaluator(labelCol='label')\n",
        "    rf= RandomForestClassifier(featuresCol='features',labelCol='label')\n",
        "    paramGrid=ParamGridBuilder().addGrid(rf.maxDepth, [20]).build()\n",
        "    fold=3\n",
        "    if isCV:\n",
        "        fold=10\n",
        "        paramGrid = (ParamGridBuilder().addGrid(rf.maxDepth, [20]) \\\n",
        "                                          .addGrid(rf.maxBins, [10, 20])\\\n",
        "                                          .addGrid(rf.numTrees, [20, 50])\\\n",
        "                                          .build())\n",
        "    \n",
        "    cv = CrossValidator(estimator=rf,\n",
        "                              estimatorParamMaps=paramGrid,\n",
        "                              evaluator=evaluator,\n",
        "                              numFolds=fold) \n",
        "    model = cv.fit(train)\n",
        "    predictions = model.transform(test)\n",
        "    bestModel = model.bestModel\n",
        "    return {\"predictions\":predictions, \"bestModel\":bestModel}\n",
        "\n",
        "\n",
        "#Implents Linear Support Vector Machine with Cross Validation\n",
        "def LSVC(train,test, isCV=False):\n",
        "    print(\">>> LinearSVC Invoked\")\n",
        "    evaluator=BinaryClassificationEvaluator(labelCol='label')\n",
        "    lsvc = LinearSVC(featuresCol='features',labelCol='label')\n",
        "    paramGrid=ParamGridBuilder().addGrid(lsvc.regParam, [0.01]).build()\n",
        "    fold=3\n",
        "    if isCV:\n",
        "        fold=10\n",
        "        paramGrid = (ParamGridBuilder().addGrid(lsvc.maxIter, [10, 15]) \\\n",
        "                                     .addGrid(lsvc.regParam, [0.1, 0.01]) \\\n",
        "                                     .build())\n",
        "    cv = CrossValidator(estimator=lsvc,\n",
        "                                  estimatorParamMaps=paramGrid,\n",
        "                                  evaluator=evaluator,\n",
        "                                  numFolds=fold) \n",
        "    model = cv.fit(train)\n",
        "    predictions = model.transform(test)\n",
        "    bestModel = model.bestModel\n",
        "    return {\"predictions\":predictions, \"bestModel\":bestModel}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Data Creation\n",
        "\n",
        "**diffSampledData** : Returns the required sampled data upon specification."
      ],
      "metadata": {
        "id": "30uZbgn24_91"
      },
      "id": "30uZbgn24_91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3bca0b-bca2-4922-8db6-4e34b1062c39",
      "metadata": {
        "id": "ac3bca0b-bca2-4922-8db6-4e34b1062c39"
      },
      "outputs": [],
      "source": [
        "def diffSampledData(data, isUnderSample=False,isOverSample=False ,isSMOTE=False, ifprint=False):\n",
        "    sampledData={}\n",
        "    print(\"\\n---Comparing data using various Sampling Techniques---\")\n",
        "\n",
        "    # print(\"\\n--NO Sampling--\")\n",
        "    # sampledData['NO_SAMPLING_APPLIED']=getFeaturesData(data, drop=True)\n",
        "\n",
        "    # Find each class data\n",
        "    dataNotFraud, dataFraud, ratio= findImbalance(data)\n",
        "    if isUnderSample:\n",
        "        print(\"\\n--Undersampling--\")\n",
        "        # Random UnderSample\n",
        "        underSampledData=randomUnderSampling(dataNotFraud,dataFraud,ratio)\n",
        "        # getAttributeCount(underSampledData,\"label\")\n",
        "        sampledData['underSampledData']=underSampledData\n",
        "        \n",
        "    if isOverSample:\n",
        "        print(\"\\n--Random OverSampling--\")\n",
        "        #Random OverSample\n",
        "        randomOverSampleddata=randomOverSample(dataNotFraud,dataFraud,int(ratio*0.75))\n",
        "        # getAttributeCount(randomOverSampleddata,\"label\")\n",
        "        sampledData['randomOverSampleddata']=randomOverSampleddata\n",
        "\n",
        "    # print(\"\\n--Complete OverSampling--\")\n",
        "    # #Complete Oversample\n",
        "    # completeOversampledData=completeOverSampling(dataNotFraud,dataFraud,ratio)\n",
        "    # getAttributeCount(completeOversampledData,\"label\")\n",
        "    # sampledData['completeOversampledData']=completeOversampledData\n",
        "    \n",
        "    if isSMOTE:\n",
        "        print(\"\\n--SMOTE OverSampling--\")\n",
        "        #SMOTE\n",
        "        oversampledDataSMOTE= smote(data, seed=24,bucketLength=200,k=3,multiplier=int(ratio*0.75))\n",
        "        sampledData['oversampledDataSMOTE']=oversampledDataSMOTE\n",
        "    \n",
        "    if ifprint:\n",
        "        if isSMOTE:\n",
        "            print(\"\\n--SMOTE OverSampling--\")\n",
        "            getAttributeCount(oversampledDataSMOTE,\"label\")\n",
        "        if isOverSample:\n",
        "            print(\"\\n--Random OverSampling--\")\n",
        "            getAttributeCount(randomOverSampleddata,\"label\")\n",
        "        # print(\"\\n--Complete OverSampling--\")\n",
        "        # getAttributeCount(completeOversampledData,\"label\")\n",
        "        if isUnderSample:\n",
        "            print(\"\\n--Undersampling--\")\n",
        "            getAttributeCount(underSampledData,\"label\")\n",
        "    return sampledData"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results \n",
        "\n",
        "1. **getResults**: Main method to run the specified Machine Learning models. Return Evaluation metrics. In case of Cross Validation, returns Best Model.\n",
        "\n",
        "2. **filldetails** : Adds all the metrics from different oversampling techniques into table.\n",
        "\n",
        "3. **printConfusionMatrix** ( ***For Visualization purposes only***): Prints confusion Matrix.\n",
        "\n",
        "4. **otherMetrics** : Caluclates Precison, Recall, Accuracy and F1 Score.\n",
        "\n",
        "5. **getEvalutions**: Evaluates predictions with labels and returns the metrics"
      ],
      "metadata": {
        "id": "6-uwjKqp5CKt"
      },
      "id": "6-uwjKqp5CKt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4b8f83-8893-4f06-bd5d-5bce1bd7e4c8",
      "metadata": {
        "id": "fe4b8f83-8893-4f06-bd5d-5bce1bd7e4c8"
      },
      "outputs": [],
      "source": [
        "def filldetails(analysisTable, predictions, sampling, model):\n",
        "    cf_matrix, ROC, accuracy, F1, precision, recall = getEvalutions(predictions)\n",
        "    print(sampling, model, ROC, accuracy, F1, precision, recall, cf_matrix)\n",
        "    analysisTable.add_row([sampling, model, ROC, accuracy, F1, precision, recall, cf_matrix])\n",
        "    \n",
        "def getResults(sampledData, test, isLR=False, isRF=False, isLSVC=False, isCatBoost=False, isLightGBM=False,isCV=False):\n",
        "    # Specify the Column Names while initializing the Table\n",
        "    analysisTable = PrettyTable([\"Sampling\", \"Model\", \"ROC\", \"accuracy\", \"F1\", \"precision\", \"recall\", \"Matrix\"])\n",
        "    results = {}\n",
        "    testData = getFeaturesData(test, drop=True)\n",
        "    testData.cache()\n",
        "    for sampling in sampledData:\n",
        "        print(\">>>>>>>>>>>>>>>>Started :\", sampling)\n",
        "        train = sampledData[sampling]\n",
        "        res={}\n",
        "        if isLR:\n",
        "        # \"LRModel\":\n",
        "            modelDataLR = LRModel(train, testData, isCV=isCV)\n",
        "            filldetails(analysisTable, modelDataLR[\"predictions\"], sampling,\"LR\")\n",
        "            res[\"LRModel\"]=modelDataLR\n",
        "        if isRF:\n",
        "            # # \"randomForest\":\n",
        "            modelDataRF = randomForest(train, testData, isCV=isCV)\n",
        "            filldetails(analysisTable, modelDataRF[\"predictions\"], sampling,\"randomForest\")\n",
        "            res[\"randomForest\"]=modelDataRF\n",
        "        if isLSVC:\n",
        "            #\"LSVC\":\n",
        "            modelDataLSVC = LSVC(train, testData, isCV=isCV)\n",
        "            filldetails(analysisTable, modelDataLSVC[\"predictions\"], sampling, \"LSVC\")\n",
        "            res[\"LSVC\"]=modelDataLSVC\n",
        "        if len(res.keys())>1:\n",
        "            results[sampling] = res\n",
        "        print(\"<<<<<<<<<<<<<<Finished :\", sampling)\n",
        "    return results, analysisTable\n",
        "\n",
        "\n",
        "\n",
        "def printConfusionMatrix(cf_matrix):\n",
        "    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                    cf_matrix.flatten()]\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "              zip(group_names,group_counts,group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')\n",
        "\n",
        "def otherMetrics(cf):\n",
        "    tp = cf[0][0]\n",
        "    fp = cf[1][0]\n",
        "    fn = cf[0][1]\n",
        "    tn = cf[1][1]\n",
        "    precision = np.round((tp)/(tp+fp),3)\n",
        "    recall =  np.round((tp)/(tp+fn),3)\n",
        "    accuracy= np.round((tp+tn)/(tp+fp+fn+tn),3)\n",
        "    F1=np.round((2*precision*recall)/(precision+recall),3)\n",
        "    return accuracy, F1, precision, recall\n",
        "\n",
        "def getEvalutions(predictions):\n",
        "    evaluator=BinaryClassificationEvaluator(labelCol='label')\n",
        "    ROC = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n",
        "    preds_and_labels = predictions.withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction').select(['prediction','label'])\n",
        "    metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "    cf_matrix=metrics.confusionMatrix().toArray()\n",
        "    # printConfusionMatrix(cf_matrix)\n",
        "    accuracy, F1, precision, recall= otherMetrics(cf_matrix)\n",
        "    return cf_matrix, np.round(ROC,3), accuracy, F1, precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo \n",
        "**Training and Testing on train_sample.csv data provided along with actual Dataset.**"
      ],
      "metadata": {
        "id": "Lr7mLHS15Its"
      },
      "id": "Lr7mLHS15Its"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03625b8a-b5fc-47f0-baf1-950a9d883acd",
      "metadata": {
        "id": "03625b8a-b5fc-47f0-baf1-950a9d883acd"
      },
      "outputs": [],
      "source": [
        "def demoData(path=\"../Data/train_sample.csv\"):\n",
        "    dataDownload = spark.read\\\n",
        "      .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
        "      .option(\"inferSchema\",True)\\\n",
        "      .option('header', 'true')\\\n",
        "      .load(path).drop(\"attributed_time\",\"click_time\").distinct().na.drop()\n",
        "    dataNotFraud, dataFraud, ratio= findImbalance(dataDownload)\n",
        "    print(\"\\n--Undersampling to create demo set--\")\n",
        "    # Random UnderSample the big data to form processable ratio for demo.\n",
        "    underSampledData=randomUnderSamplingWithoutTransformation(dataNotFraud,dataFraud,int(ratio/8))\n",
        "    getCompleteSummary(underSampledData)\n",
        "    trainSample,testSample=stratifiedTrainTestSplit(underSampledData, ifprint=False)\n",
        "    sampledData=diffSampledData(trainSample,isUnderSample=True,isOverSample=False ,isSMOTE=False, ifprint=False)\n",
        "    results, analysisTable= getResults(sampledData,testSample,isLR=True, isRF=False, isLSVC=False)\n",
        "    print(\"\\n________________RESULTS______________\\n\",analysisTable)\n",
        "    return results, analysisTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744cb95e-306a-4762-b1e4-9af5d7b7405c",
      "metadata": {
        "id": "744cb95e-306a-4762-b1e4-9af5d7b7405c",
        "outputId": "0f1b97ab-3a4e-4151-94f7-49c4440c892b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Fraud: 227\n",
            "Count Not Fraud: 97693\n",
            "Ratio: 430\n",
            "\n",
            "--Undersampling to create demo set--\n",
            "Summary\n",
            "_________\n",
            "+-------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+\n",
            "|summary|               ip|              app|           device|                os|          channel|      is_attributed|\n",
            "+-------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+\n",
            "|  count|             2094|             2094|             2094|              2094|             2094|               2094|\n",
            "|   mean|99453.89923591213|14.14660936007641|17.64517669531996| 22.39541547277937|258.7679083094556|0.10840496657115568|\n",
            "| stddev|78809.85413920505|18.31663940219889| 223.695495718449|56.105595429545566| 130.619592252793| 0.3109654468266364|\n",
            "|    min|               36|                1|                0|                 0|                3|                  0|\n",
            "|    25%|            41369|                3|                1|                13|              135|                  0|\n",
            "|    50%|            84911|               12|                1|                18|              245|                  0|\n",
            "|    75%|           125222|               18|                1|                20|              377|                  0|\n",
            "|    max|           362527|              261|             3866|               866|              497|                  1|\n",
            "+-------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+\n",
            "\n",
            "_________\n",
            "Total:  2094\n",
            "Left After Dropping: 2094\n",
            "% Of Drops:  0.0\n",
            "% of drop per column\n",
            "_________\n",
            "Unique Values for each column in the table\n",
            "+----+---+------+---+-------+-------------+\n",
            "|  ip|app|device| os|channel|is_attributed|\n",
            "+----+---+------+---+-------+-------------+\n",
            "|1886| 64|    32| 65|    124|            2|\n",
            "+----+---+------+---+-------+-------------+\n",
            "\n",
            "_________\n",
            "Number of values in is_attributed for each label.\n",
            "_________\n",
            "Stats for is attributed:\n",
            "+-------------+-----+\n",
            "|is_attributed|count|\n",
            "+-------------+-----+\n",
            "|            0| 1867|\n",
            "|            1|  227|\n",
            "+-------------+-----+\n",
            "\n",
            "_________\n",
            "\n",
            "-----TRAIN TEST SPLIT STARTED----\n",
            "Count Fraud: 227\n",
            "Count Not Fraud: 1867\n",
            "Ratio: 8\n",
            "\n",
            "----SAMPLES IN TRAIN----\n",
            "Count Fraud: 186\n",
            "Count Not Fraud: 1486\n",
            "Ratio: 7\n",
            "\n",
            "----SAMPLES IN TEST-----\n",
            "Count Fraud: 41\n",
            "Count Not Fraud: 381\n",
            "Ratio: 9\n",
            "\n",
            "---Comparing data using various Sampling Techniques---\n",
            "Count Fraud: 186\n",
            "Count Not Fraud: 1486\n",
            "Ratio: 7\n",
            "\n",
            "--Undersampling--\n",
            ">>>>>>>>>>>>>>>>Started : underSampledData\n",
            ">>> LRModel Invoked\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "underSampledData LR 0.853 0.849 0.912 0.964 0.865 [[296.  46.]\n",
            " [ 11.  25.]]\n",
            "<<<<<<<<<<<<<<Finished : underSampledData\n",
            "\n",
            "________________RESULTS______________\n",
            " +------------------+-------+-------+----------+-------+-----------+--------+---------------+\n",
            "|     Sampling     | Model |  ROC  | accuracy |   F1  | precision | recall |     Matrix    |\n",
            "+------------------+-------+-------+----------+-------+-----------+--------+---------------+\n",
            "| underSampledData |   LR  | 0.853 |  0.849   | 0.912 |   0.964   | 0.865  |  [[296.  46.] |\n",
            "|                  |       |       |          |       |           |        |  [ 11.  25.]] |\n",
            "+------------------+-------+-------+----------+-------+-----------+--------+---------------+\n"
          ]
        }
      ],
      "source": [
        "resultsDemo, analysisTableDemo= demoData(path='/content/drive/MyDrive/Final Project CS 657/talkingdata-adtracking-fraud-detection/train_sample.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Million Records\n",
        "**Training and Testing on sampled 6 Million records from train.csv**"
      ],
      "metadata": {
        "id": "NZAy3Vm25k_j"
      },
      "id": "NZAy3Vm25k_j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987c915d-b952-49c5-9fe6-3ff025290568",
      "metadata": {
        "id": "987c915d-b952-49c5-9fe6-3ff025290568"
      },
      "outputs": [],
      "source": [
        "def RUN6MTEST(path=\"../Data/Sampled_data.parquet\"):\n",
        "    dataDownload=spark.read.parquet(path)\n",
        "    getCompleteSummary(dataDownload)\n",
        "    trainSample,testSample=stratifiedTrainTestSplit(dataDownload, ifprint=False)\n",
        "    sampledData=diffSampledData(trainSample, isUnderSample=False,isOverSample=False,isSMOTE=True, ifprint=False)\n",
        "    results, analysisTable= getResults(sampledData,testSample,isLR=False, isRF=True, isLSVC=False)\n",
        "    print(\"\\n________________RESULTS______________\\n\",analysisTable)\n",
        "    return results, analysisTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b6168-1c38-463a-b8fd-28ed4ac7c63a",
      "metadata": {
        "id": "540b6168-1c38-463a-b8fd-28ed4ac7c63a",
        "outputId": "5059823b-f200-4c78-d509-168b74dacf07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary\n",
            "_________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|summary|                ip|               app|            device|                os|           channel|      is_attributed|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|  count|            616913|            616913|            616913|            616913|            616913|             616913|\n",
            "|   mean|124889.97044477909|17.759027610051984|22.148653051564807|24.069484676121267|  260.603418958589|0.27552183208977604|\n",
            "| stddev| 92713.99720309858|  24.5428670492717|232.85310325314362| 54.08001962606024|135.62297249295284| 0.4467772103566922|\n",
            "|    min|                 1|                 0|                 0|                 0|                 0|                  0|\n",
            "|    25%|             50737|                 6|                 1|                13|               135|                  0|\n",
            "|    50%|            103077|                13|                 1|                19|               237|                  0|\n",
            "|    75%|            183889|                19|                 1|                25|               379|                  1|\n",
            "|    max|            364778|               758|              4216|               866|               498|                  1|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "\n",
            "_________\n",
            "Total:  616913\n",
            "Left After Dropping: 616913\n",
            "% Of Drops:  0.0\n",
            "% of drop per column\n",
            "_________\n",
            "Unique Values for each column in the table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+------+---+-------+-------------+\n",
            "|    ip|app|device| os|channel|is_attributed|\n",
            "+------+---+------+---+-------+-------------+\n",
            "|155161|326|  1320|224|    174|            2|\n",
            "+------+---+------+---+-------+-------------+\n",
            "\n",
            "_________\n",
            "Number of values in is_attributed for each label.\n",
            "_________\n",
            "Stats for is attributed:\n",
            "+-------------+------+\n",
            "|is_attributed| count|\n",
            "+-------------+------+\n",
            "|            1|169973|\n",
            "|            0|446940|\n",
            "+-------------+------+\n",
            "\n",
            "_________\n",
            "\n",
            "-----TRAIN TEST SPLIT STARTED----\n",
            "Count Fraud: 169973\n",
            "Count Not Fraud: 446940\n",
            "Ratio: 2\n",
            "\n",
            "----SAMPLES IN TRAIN----\n",
            "Count Fraud: 136201\n",
            "Count Not Fraud: 357669\n",
            "Ratio: 2\n",
            "\n",
            "----SAMPLES IN TEST-----\n",
            "Count Fraud: 33772\n",
            "Count Not Fraud: 89271\n",
            "Ratio: 2\n",
            "\n",
            "---Comparing data using various Sampling Techniques---\n",
            "Count Fraud: 136201\n",
            "Count Not Fraud: 357669\n",
            "Ratio: 2\n",
            "\n",
            "--SMOTE OverSampling--\n",
            "All columns are been covered.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating New Samples\n",
            "Samples Generation Complete.\n",
            ">>>>>>>>>>>>>>>>Started : oversampledDataSMOTE\n",
            ">>> RandomForest Invoked\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:33:06 WARN DAGScheduler: Broadcasting large task binary with size 1114.9 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:33:15 WARN DAGScheduler: Broadcasting large task binary with size 1723.4 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:33:26 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:33:39 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:33:56 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:34:19 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5354:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:34:37 WARN DAGScheduler: Broadcasting large task binary with size 1201.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:34:47 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5360:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:35:10 WARN DAGScheduler: Broadcasting large task binary with size 1476.8 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:35:21 WARN DAGScheduler: Broadcasting large task binary with size 14.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5366:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:35:57 WARN DAGScheduler: Broadcasting large task binary with size 1767.9 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:36:12 WARN DAGScheduler: Broadcasting large task binary with size 19.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5372:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:36:53 WARN DAGScheduler: Broadcasting large task binary with size 2037.7 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:37:09 WARN DAGScheduler: Broadcasting large task binary with size 23.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5378:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:37:49 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5384:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:38:07 WARN DAGScheduler: Broadcasting large task binary with size 29.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5384:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:39:06 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5390:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:39:31 WARN DAGScheduler: Broadcasting large task binary with size 34.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5390:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:40:24 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5395:=================================================>  (192 + 8) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:42:23 WARN DAGScheduler: Broadcasting large task binary with size 14.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:47:29 WARN DAGScheduler: Broadcasting large task binary with size 1153.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:47:39 WARN DAGScheduler: Broadcasting large task binary with size 1800.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:47:51 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:48:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:48:26 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:48:52 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5528:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:49:17 WARN DAGScheduler: Broadcasting large task binary with size 1250.3 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:49:30 WARN DAGScheduler: Broadcasting large task binary with size 11.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5534:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1536.2 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:50:14 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5540:====================================================(204 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:50:50 WARN DAGScheduler: Broadcasting large task binary with size 1828.0 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:51:06 WARN DAGScheduler: Broadcasting large task binary with size 19.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5546:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:51:51 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5552:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:52:12 WARN DAGScheduler: Broadcasting large task binary with size 24.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5552:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:53:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5558:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:53:33 WARN DAGScheduler: Broadcasting large task binary with size 30.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5558:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:54:35 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5564:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:55:01 WARN DAGScheduler: Broadcasting large task binary with size 35.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5564:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:56:17 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5569:==================================================> (196 + 4) / 200]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 21:58:35 WARN DAGScheduler: Broadcasting large task binary with size 14.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:04:17 WARN DAGScheduler: Broadcasting large task binary with size 1163.3 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:04:29 WARN DAGScheduler: Broadcasting large task binary with size 1805.9 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:04:43 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:05:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:05:23 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:05:51 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5702:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1233.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:06:20 WARN DAGScheduler: Broadcasting large task binary with size 11.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5708:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:06:43 WARN DAGScheduler: Broadcasting large task binary with size 1499.2 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:06:55 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5714:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:07:29 WARN DAGScheduler: Broadcasting large task binary with size 1764.9 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:07:45 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5720:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:08:28 WARN DAGScheduler: Broadcasting large task binary with size 2024.8 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:08:46 WARN DAGScheduler: Broadcasting large task binary with size 24.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5726:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:09:30 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5732:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:09:47 WARN DAGScheduler: Broadcasting large task binary with size 29.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5732:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:10:44 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5738:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:11:06 WARN DAGScheduler: Broadcasting large task binary with size 34.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5738:===================================================>(203 + 1) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:12:05 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5744:>                                                     (0 + 0) / 204]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:14:11 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:26:47 WARN DAGScheduler: Broadcasting large task binary with size 1112.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:26:51 WARN DAGScheduler: Broadcasting large task binary with size 1729.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:26:55 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:01 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:07 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5897:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:14 WARN DAGScheduler: Broadcasting large task binary with size 1024.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:16 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5903:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1342.8 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:27 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5909:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:37 WARN DAGScheduler: Broadcasting large task binary with size 1688.2 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:41 WARN DAGScheduler: Broadcasting large task binary with size 15.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5915:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:51 WARN DAGScheduler: Broadcasting large task binary with size 2043.0 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:27:55 WARN DAGScheduler: Broadcasting large task binary with size 20.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5921:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:06 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5927:>                                                      (0 + 0) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:11 WARN DAGScheduler: Broadcasting large task binary with size 26.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5927:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:25 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5933:>                                                      (0 + 0) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:31 WARN DAGScheduler: Broadcasting large task binary with size 32.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5933:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:52 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5939:>                                                      (0 + 0) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:28:59 WARN DAGScheduler: Broadcasting large task binary with size 39.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5939:====================================================> (26 + 1) / 27]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:29:17 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5958:=============================================>        (11 + 2) / 13]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:34:50 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:34:56 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:34:58 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5971:==========================================>             (3 + 1) / 4]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:34:59 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:35:00 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5975:>                                                       (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "oversampledDataSMOTE randomForest 0.961 0.933 0.955 0.939 0.971 [[86665.  2606.]\n",
            " [ 5656. 28116.]]\n",
            "<<<<<<<<<<<<<<Finished : oversampledDataSMOTE\n",
            "\n",
            "________________RESULTS______________\n",
            " +----------------------+--------------+-------+----------+-------+-----------+--------+-------------------+\n",
            "|       Sampling       |    Model     |  ROC  | accuracy |   F1  | precision | recall |       Matrix      |\n",
            "+----------------------+--------------+-------+----------+-------+-----------+--------+-------------------+\n",
            "| oversampledDataSMOTE | randomForest | 0.961 |  0.933   | 0.955 |   0.939   | 0.971  |  [[86665.  2606.] |\n",
            "|                      |              |       |          |       |           |        |  [ 5656. 28116.]] |\n",
            "+----------------------+--------------+-------+----------+-------+-----------+--------+-------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "results6M, analysisTable6M= RUN6MTEST()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 26 Million Records\n",
        "**Training and Testing on sampled 26 Million records from train.csv**\n"
      ],
      "metadata": {
        "id": "borhjs_R5sGl"
      },
      "id": "borhjs_R5sGl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fafda20b-221a-4d75-a03d-ee18e1c58f23",
      "metadata": {
        "id": "fafda20b-221a-4d75-a03d-ee18e1c58f23"
      },
      "outputs": [],
      "source": [
        "def RUN26MTEST(path=\"../Data/Sampled25M.parquet\"):\n",
        "    dataDownload=spark.read.parquet(path)\n",
        "    getCompleteSummary(dataDownload)\n",
        "    trainSample,testSample=stratifiedTrainTestSplit(dataDownload, ifprint=False)\n",
        "    sampledData=diffSampledData(trainSample, isUnderSample=False,isOverSample=True, ifprint=False)\n",
        "    results, analysisTable= getResults(sampledData,testSample,isLR=False, isRF=True, isLSVC=False)\n",
        "    print(\"\\n________________RESULTS______________\\n\",analysisTable)\n",
        "    return results, analysisTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4b3a46-b9f6-4241-a79d-fc99bf60ef80",
      "metadata": {
        "id": "4c4b3a46-b9f6-4241-a79d-fc99bf60ef80",
        "outputId": "4058970f-c960-44f0-c315-c8730ddbba4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary\n",
            "_________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+-----------------+------------------+------------------+------------------+-------------------+\n",
            "|summary|                ip|              app|            device|                os|           channel|      is_attributed|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+-------------------+\n",
            "|  count|           2570962|          2570962|           2570962|           2570962|           2570962|            2570962|\n",
            "|   mean|117578.32723781993|15.83455609223318|20.505753099423483|24.018647883554873| 269.1028957254133|0.16480679216573407|\n",
            "| stddev|  88516.5227112953|21.98906805298176|235.46908212340674|  54.1577769104347|137.00831860255715|0.37100615488199506|\n",
            "|    min|                 1|                0|                 0|                 0|                 0|                  0|\n",
            "|    25%|             48418|                3|                 1|                13|               135|                  0|\n",
            "|    50%|             97919|               12|                 1|                18|               245|                  0|\n",
            "|    75%|            170321|               18|                 1|                25|               402|                  0|\n",
            "|    max|            364778|              768|              4225|               916|               498|                  1|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+-------------------+\n",
            "\n",
            "_________\n",
            "Total:  2570962\n",
            "Left After Dropping: 2570962\n",
            "% Of Drops:  0.0\n",
            "% of drop per column\n",
            "_________\n",
            "Unique Values for each column in the table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+------+---+-------+-------------+\n",
            "|    ip|app|device| os|channel|is_attributed|\n",
            "+------+---+------+---+-------+-------------+\n",
            "|265843|424|  1999|307|    182|            2|\n",
            "+------+---+------+---+-------+-------------+\n",
            "\n",
            "_________\n",
            "Number of values in is_attributed for each label.\n",
            "_________\n",
            "Stats for is attributed:\n",
            "+-------------+-------+\n",
            "|is_attributed|  count|\n",
            "+-------------+-------+\n",
            "|            1| 423712|\n",
            "|            0|2147250|\n",
            "+-------------+-------+\n",
            "\n",
            "_________\n",
            "\n",
            "-----TRAIN TEST SPLIT STARTED----\n",
            "Count Fraud: 423712\n",
            "Count Not Fraud: 2147250\n",
            "Ratio: 5\n",
            "\n",
            "----SAMPLES IN TRAIN----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Fraud: 338751\n",
            "Count Not Fraud: 1716450\n",
            "Ratio: 5\n",
            "\n",
            "----SAMPLES IN TEST-----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Fraud: 84961\n",
            "Count Not Fraud: 430800\n",
            "Ratio: 5\n",
            "\n",
            "---Comparing data using various Sampling Techniques---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Fraud: 338751\n",
            "Count Not Fraud: 1716450\n",
            "Ratio: 5\n",
            "\n",
            "--Random OverSampling--\n",
            ">>>>>>>>>>>>>>>>Started : randomOverSampleddata\n",
            ">>> RandomForest Invoked\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:36:32 WARN DAGScheduler: Broadcasting large task binary with size 1398.9 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:36:42 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:36:54 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:37:13 WARN DAGScheduler: Broadcasting large task binary with size 6.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6051:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:37:29 WARN DAGScheduler: Broadcasting large task binary with size 1438.2 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:37:31 WARN DAGScheduler: Broadcasting large task binary with size 10.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6053:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:37:57 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:38:01 WARN DAGScheduler: Broadcasting large task binary with size 15.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6055:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:38:26 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6057:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:38:33 WARN DAGScheduler: Broadcasting large task binary with size 21.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6057:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:39:05 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6059:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:39:14 WARN DAGScheduler: Broadcasting large task binary with size 30.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6059:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:39:51 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6061:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:40:02 WARN DAGScheduler: Broadcasting large task binary with size 40.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6061:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:40:47 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6063:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:41:00 WARN DAGScheduler: Broadcasting large task binary with size 51.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6063:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:41:48 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6065:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:42:04 WARN DAGScheduler: Broadcasting large task binary with size 64.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6065:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:42:59 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6067:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:43:18 WARN DAGScheduler: Broadcasting large task binary with size 76.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6067:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:44:14 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:44:25 WARN DAGScheduler: Broadcasting large task binary with size 18.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:45:44 WARN DAGScheduler: Broadcasting large task binary with size 1404.2 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:45:54 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:46:07 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:46:20 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6111:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:46:37 WARN DAGScheduler: Broadcasting large task binary with size 1423.7 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:46:40 WARN DAGScheduler: Broadcasting large task binary with size 10.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6113:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:47:01 WARN DAGScheduler: Broadcasting large task binary with size 2044.3 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:47:04 WARN DAGScheduler: Broadcasting large task binary with size 15.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6115:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:47:31 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:47:37 WARN DAGScheduler: Broadcasting large task binary with size 21.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6117:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:48:02 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6119:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:48:10 WARN DAGScheduler: Broadcasting large task binary with size 29.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6119:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:48:41 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6121:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:48:51 WARN DAGScheduler: Broadcasting large task binary with size 39.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6121:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:49:30 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6123:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:49:43 WARN DAGScheduler: Broadcasting large task binary with size 51.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6123:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:50:29 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6125:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:50:46 WARN DAGScheduler: Broadcasting large task binary with size 63.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6125:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:51:39 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6127:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:51:57 WARN DAGScheduler: Broadcasting large task binary with size 75.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6127:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:52:49 WARN DAGScheduler: Broadcasting large task binary with size 6.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:53:03 WARN DAGScheduler: Broadcasting large task binary with size 18.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:54:20 WARN DAGScheduler: Broadcasting large task binary with size 1408.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:54:30 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:54:41 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:54:56 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6171:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1406.6 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:15 WARN DAGScheduler: Broadcasting large task binary with size 10.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6173:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:32 WARN DAGScheduler: Broadcasting large task binary with size 2035.3 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:36 WARN DAGScheduler: Broadcasting large task binary with size 15.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6175:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:53 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:55:59 WARN DAGScheduler: Broadcasting large task binary with size 21.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6177:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:56:20 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6179:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:56:30 WARN DAGScheduler: Broadcasting large task binary with size 30.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6179:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:57:02 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6181:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:57:14 WARN DAGScheduler: Broadcasting large task binary with size 40.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6181:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:57:47 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6183:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:57:55 WARN DAGScheduler: Broadcasting large task binary with size 51.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6183:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:58:34 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6185:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:58:43 WARN DAGScheduler: Broadcasting large task binary with size 63.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6185:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:59:30 WARN DAGScheduler: Broadcasting large task binary with size 6.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6187:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 22:59:42 WARN DAGScheduler: Broadcasting large task binary with size 76.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6187:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:00:27 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:00:34 WARN DAGScheduler: Broadcasting large task binary with size 19.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:02:19 WARN DAGScheduler: Broadcasting large task binary with size 1399.5 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:02:33 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:02:54 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:03:18 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6231:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:03:45 WARN DAGScheduler: Broadcasting large task binary with size 1481.1 KiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:03:47 WARN DAGScheduler: Broadcasting large task binary with size 10.4 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6233:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:04:12 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:04:16 WARN DAGScheduler: Broadcasting large task binary with size 15.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6235:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:04:48 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:04:54 WARN DAGScheduler: Broadcasting large task binary with size 22.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6237:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:05:31 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6239:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:05:39 WARN DAGScheduler: Broadcasting large task binary with size 31.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6239:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:06:15 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6241:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:06:26 WARN DAGScheduler: Broadcasting large task binary with size 42.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6241:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:07:15 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6243:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:07:27 WARN DAGScheduler: Broadcasting large task binary with size 55.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6243:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:08:22 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6245:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:08:37 WARN DAGScheduler: Broadcasting large task binary with size 68.8 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6245:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:09:44 WARN DAGScheduler: Broadcasting large task binary with size 7.2 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6247:>                                                      (0 + 0) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:10:06 WARN DAGScheduler: Broadcasting large task binary with size 82.7 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6247:===================================================>  (19 + 1) / 20]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:11:27 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:11:41 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:11:53 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:11:58 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:12:03 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6262:=================================================>     (9 + 1) / 10]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:12:09 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/12/05 23:12:10 WARN DAGScheduler: Broadcasting large task binary with size 19.5 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6266:>                                                       (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "randomOverSampleddata randomForest 0.969 0.95 0.97 0.971 0.969 [[417358.  13442.]\n",
            " [ 12558.  72403.]]\n",
            "<<<<<<<<<<<<<<Finished : randomOverSampleddata\n",
            "\n",
            "________________RESULTS______________\n",
            " +-----------------------+--------------+-------+----------+------+-----------+--------+---------------------+\n",
            "|        Sampling       |    Model     |  ROC  | accuracy |  F1  | precision | recall |        Matrix       |\n",
            "+-----------------------+--------------+-------+----------+------+-----------+--------+---------------------+\n",
            "| randomOverSampleddata | randomForest | 0.969 |   0.95   | 0.97 |   0.971   | 0.969  |  [[417358.  13442.] |\n",
            "|                       |              |       |          |      |           |        |  [ 12558.  72403.]] |\n",
            "+-----------------------+--------------+-------+----------+------+-----------+--------+---------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "results26M, analysisTable26M= RUN26MTEST()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}